{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcd2f47-dd99-4db9-aac8-fe6a3064ed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmwapi is a MIT-licensed library provides a very simple convenience wrapper around the MediaWiki API, including support for authenticated sessions. \\nIt requires Python 3 and that your wiki is using MediaWiki 1.15.3 or greater.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install all the necessary dependencies\n",
    "!pip install mwapi\n",
    "!pip install pywikibot\n",
    "'''\n",
    "mwapi is a MIT-licensed library provides a very simple convenience wrapper around the MediaWiki API, including support for authenticated sessions. \n",
    "It requires Python 3 and that your wiki is using MediaWiki 1.15.3 or greater.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4d1979-987b-4b21-8808-0ce942c3696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary dependencies\n",
    "import requests\n",
    "import json\n",
    "import mwapi #importing mwapi\n",
    "import re #importing regular expression\n",
    "import pywikibot #import pywikibot dependencies\n",
    "from pywikibot.data.sparql import SparqlQuery #import dependencies for sparql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76271f9e-a638-488e-b8ea-57e30b64ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_list(title, lang) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    gets all the categories of the file using api: https://commons.wikimedia.org/w/api.php\n",
    "\n",
    "    Args:\n",
    "        title (string): the title of the commons file\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "        categories_list ([string]): list containing all the categories from the api associated with the file\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\":\"categories\",\n",
    "            \"titles\":title,\n",
    "            \"clshow\": \"hidden\", #this shows part of the categories not all changing this to !hidden shows the remaining categories\n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = session.get(params) #get request for the wikiapi\n",
    "    response_pages = response['query']['pages'] \n",
    "    page_id = list(response_pages.keys())[0] # gets the pageid\n",
    "    categories = response_pages[page_id]['categories'] #gets values of the categories the file belongs to\n",
    "    categories_list = [categories_item['title'] for categories_item in categories] # loops through the categories list from the api to get the title\n",
    "    \n",
    "    return categories_list\n",
    "\n",
    "#get_categories_list('File:Açude_Cedro_-_Detalhe_do_acabamento_da_barragem_principal.jpg', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124a01c-b050-47fd-bc96-84f171bf98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_categories_list(title, lang) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    gets all the hidden categories of the file using api: https://commons.wikimedia.org/w/api.php\n",
    "\n",
    "    Args:\n",
    "        title (string): the title of the commons file\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "        categories_hidden_list ([string]): list containing all the hidden categories from the api associated with the file\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\":\"categories\",\n",
    "            \"titles\":title,\n",
    "            \"clshow\": \"!hidden\", #Which kind of categories to show.\n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = session.get(params) #get request for the wikiapi\n",
    "    response_pages = response['query']['pages'] \n",
    "    page_id = list(response_pages.keys())[0] # gets the pageid\n",
    "    categories = response_pages[page_id]['categories'] #gets values of the categories the file belongs to\n",
    "    categories_hidden_list = [categories_item['title'] for categories_item in categories]  # loops through the categories list from the api to get the title\n",
    "    \n",
    "    return categories_hidden_list\n",
    "\n",
    "#get_hidden_categories_list('File:Açude_Cedro_-_Detalhe_do_acabamento_da_barragem_principal.jpg', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84669114-62a3-4c8c-9a3e-c78d87eaf1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_item(title, lang) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    metadata of the file on the homepage using api: https://commons.wikimedia.org/w/api.php\n",
    "\n",
    "    Args:\n",
    "        title (string): the title of the commons file\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "        all metadata and their values as strings\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang), #lang can vary depending on the api and language working with eg lang can be fr, as, commons, en etc\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\":\"imageinfo\", #Returns file information and upload history. from the api https://commons.wikimedia.org/w/api.php?action=help&modules=query\n",
    "            \"titles\":title,\n",
    "            \"iiprop\":\"metadata\", #Which file information to get eg metadata, size, dimension, mime\n",
    "            \"iimetadataversion\":\"latest\", #Version of metadata to use. If latest is specified, use latest version. Defaults to 1 for backwards compatibility\n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = session.get(params)\n",
    "    response_imageinfo = response['query']['pages']  #selects the query -> pages dictionary from the api response\n",
    "    page_id = list(response_imageinfo.keys())[0] #automates how to extract information using the pageid than manually entering it\n",
    "    imageinfo = response_imageinfo[page_id]['imageinfo']\n",
    "    \n",
    "    for response_value in imageinfo:\n",
    "        response_item = response_value['metadata'] #selects the metadata dictionary\n",
    "        for metadata_value in response_item: #loops through this list\n",
    "            if type(metadata_value['value']) == list: #some of the metadata further have a list of dictionaries that give more information\n",
    "                for i in range (len(metadata_value['value'])-1): # looping through this list and extracting these informations\n",
    "                    print(metadata_value[\"name\"], '-> ', metadata_value['value'][i]['name'], '->', metadata_value['value'][i]['value'])\n",
    "                    \n",
    "            else: #conditional when the value of the metadata is not a list\n",
    "                print(metadata_value[\"name\"], '-> ', metadata_value['value'])\n",
    "            \n",
    "            \n",
    "#get_metadata_item('File:Açude_Cedro_-_Detalhe_do_acabamento_da_barragem_principal.jpg', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5c205-e7bf-42ae-8396-83ef2d78087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_data(title, lang) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    summary data of te file on the homepage using api: https://commons.wikimedia.org/w/api.php\n",
    "\n",
    "    Args:\n",
    "        title (string): the title of the commons file\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "        DateTimeOriginal|Categories|License|LicenseUrl|ImageDescription|Credit|GPSLatitude|GPSLongitude\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\":\"imageinfo\",\n",
    "            \"titles\": title,\n",
    "            \"iiprop\":\"extmetadata|commonmetadata|size|dimensions|mime|mediatype\", #the type of file information to get\n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "\n",
    "    response = session.get(params)\n",
    "    response_pages = response['query']['pages'] \n",
    "    \n",
    "    page_id = list(response_pages.keys())[0]  # automates the pageid for each file/a file \n",
    "    imageinfo = response_pages[page_id]['imageinfo'] # retrieves the value of item imageinfo\n",
    "    \n",
    "    for response_item in imageinfo: #loops through the imageinfo list\n",
    "        for response_item_keys in list(response_item.keys()): #automate the keys of the response_item dictionary to get the values\n",
    "            \n",
    "            if type(response_item[response_item_keys]) == list: #conditional statement if the values is a list\n",
    "                for response_item_nestedkeys in response_item[response_item_keys]: #loop through this list\n",
    "                    if type(response_item_nestedkeys['value']) == list:  #conditional statement if the value of the above list is a list\n",
    "                        for nested_keys in response_item_nestedkeys['value']: #loop through this list\n",
    "                            print(response_item_nestedkeys['name'], '-> ', nested_keys['name'], '-> ', nested_keys['value'])\n",
    "                    else:\n",
    "                        print(response_item_nestedkeys['name'], ' -> ', response_item_nestedkeys['value'])\n",
    "                    \n",
    "            elif isinstance(response_item[response_item_keys], dict): #conditional statement if the values is a dictionary\n",
    "                for response_itemkeys in list(response_item[response_item_keys].keys()): #automate the keys of the response_itemkeys dictionary to get the values\n",
    "                    if response_itemkeys == 'ImageDescription': #conditional statement if the dictionary value is a ImageDescription inorder to use this particular regex to extract image description\n",
    "                        try: #the imagedescription difer for different artist\n",
    "                            image_value = re.findall(r\"(.*?)<a\\b[^>]*>([^<]+)<\\/a>\", response_item[response_item_keys][response_itemkeys]['value']) # regex to extract the image description from anchor html tags\n",
    "                            print(response_itemkeys, \"-> \", image_value[0][0], image_value[0][1])\n",
    "\n",
    "                        except:\n",
    "                            print(response_itemkeys, \"-> \", response_item[response_item_keys][response_itemkeys]['value'])\n",
    "                            \n",
    "                    elif response_itemkeys == 'Artist': #conditional statement if the dictionary value is an artist inorder to use this particular regex to extract artist name\n",
    "                        try: #the artist difer for different artist\n",
    "                            artist_value = re.findall(r\"<a\\b[^>]*>([^<]+)<\\/a>\", response_item[response_item_keys][response_itemkeys]['value']) # regex to extract the artist from anchor html tags\n",
    "                            print(response_itemkeys, '-> ', artist_value[0])\n",
    "                        except:\n",
    "                            artist_value = re.findall(r\"<span\\b[^>]*>([^<]+)<\\/span>\", response_item[response_item_keys][response_itemkeys]['value']) # regex to extract the artist from anchor html tags\n",
    "                            print(response_itemkeys, '-> ', artist_value[0])\n",
    "                    \n",
    "                    elif response_itemkeys == 'Credit': #conditional statement if the dictionary value is a credit property inorder to use this particular regex to extract credit\n",
    "                        try: #the credit difer for different artist\n",
    "                            credit_value = re.findall(r\"<span\\b[^>]*>([^<]+)<\\/span>\", response_item[response_item_keys][response_itemkeys]['value']) # regex to extract the credit from span html tags\n",
    "                            print(response_itemkeys, \"-> \", credit_value[0])\n",
    "                        except:\n",
    "                            credit_value = re.findall(r\"(.*?)<a\\b[^>]*>([^<]+)<\\/a>\", response_item[response_item_keys][response_itemkeys]['value']) # regex to extract the credit from span html tags\n",
    "                            print(response_itemkeys, \"-> \", credit_value[0][0], credit_value[0][1])\n",
    "                            \n",
    "                    else:\n",
    "                        print(response_itemkeys, ' -> ', response_item[response_item_keys][response_itemkeys]['value'])\n",
    "                        \n",
    "            else:\n",
    "                print(response_item_keys, ' -> ', response_item[response_item_keys])\n",
    "    \n",
    "get_all_files_data('File:Açude_Cedro_-_Detalhe_do_acabamento_da_barragem_principal.jpg', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f453b9b-9c54-402c-85f9-f1018438d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_files_subcat(cat_title, lang='commons') -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    files/images of wikidata item for subcategory\n",
    "\n",
    "    Args:\n",
    "        cat_title (string): the title/name of the category of interest\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "         files_list ([string]): the title of the files/images of wikidata item for category(subcategory) for each wikidata id in a category\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "    params_1 = {\n",
    "                \"action\": \"query\",\n",
    "                \"generator\":\"categorymembers\", #Get information about all categories used in the page\n",
    "                \"gcmlimit\": 500,\n",
    "                \"gcmtitle\": cat_title,\n",
    "                \"gcmnamespace\": 6,\n",
    "                \"format\": \"json\",\n",
    "        }\n",
    "    \n",
    "    response = session.get(params_1)\n",
    "    pageids = list(response['query']['pages'].keys())\n",
    "    \n",
    "    files_list = [response['query']['pages'][str(pageid)]['title'] for pageid in pageids]\n",
    "        \n",
    "    return files_list\n",
    "\n",
    "#get_all_files_subcat('Category:2021 in São Paulo (state)', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c5545-52a4-4d7f-8a89-526d1f05d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_cat(cat, lang) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    files/images of all the subcategory in a category\n",
    "\n",
    "    Args:\n",
    "        cat_title (string): the title/name of all the files in each subcategory in a category of interest\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "         cat_file_list([string]): the title of the files/images of wikidata item for each subcategory in a category\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"list\":\"categorymembers\", #Get information about all categories used in the page\n",
    "            \"cmtitle\": cat,\n",
    "            \"cmtype\": 'subcat', #get sub categories in a category\n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = session.get(params) #get request for the wikiapi to get the category members pageid\n",
    "    category_member = response['query']['categorymembers']\n",
    "    \n",
    "    cat_file_list= sum([get_all_files_subcat(category_item['title'], lang='commons') for category_item in category_member], []) #add more files to the list to create the category list\n",
    "    '''for category_item in category_member:\n",
    "        cat_title = category_item['title']\n",
    "        files = get_all_files_subcat(cat_title, lang='commons')\n",
    "        cat_file_list += files '''\n",
    "        \n",
    "    return cat_file_list\n",
    "\n",
    "#get_all_files_cat('Category:Top_contributors_of_Wiki_Loves_Monuments_2020_in_Brazil', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77916e28-4aba-4b33-be8d-0a3513444b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_wikidata(cat, lang) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    unique wikidata item for each image in all subcategory of a category of interest\n",
    "\n",
    "    Args:\n",
    "        cat (string): the title/name of the category of interest\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "        new_wikidata_list ([string]): the unique wikidata item for each image in a category\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"generator\":\"categorymembers\", #Get information about all categories used in the page\n",
    "            \"gcmlimit\": 500,\n",
    "            \"gcmtitle\": cat,\n",
    "            \"gcmnamespace\": 6, #get files as namespace 6 is for files note it can also be used to get subcategories \n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = session.get(params) #get request for the wikiapi to get the category members pageid\n",
    "    pageids = list(response['query']['pages'].keys()) #automatically get the pageids\n",
    "    \n",
    "    wikidata_list=[]\n",
    "    for pageid in pageids:\n",
    "        pageid_number = \"M\" + str(pageid)\n",
    "        params_1 = {\n",
    "            \"action\": \"wbgetentities\", #Gets the data for multiple Wikibase entities.\n",
    "            \"ids\": str(pageid_number),\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "\n",
    "        response_1 = session.get(params_1) #get request for the wikiapi to get the data/information about this pageid_number passed\n",
    "        pagetitle = response_1.get('entities').get(pageid_number).get('title')\n",
    "        property_depict = response_1.get('entities').get(pageid_number).get('statements').get('P180', 'XX') #P180 is the wikidata property number for depicts\n",
    "        \n",
    "        if \"XX\" not in str(property_depict):\n",
    "            \n",
    "            depictslist=[]\n",
    "            for dict_place in range(0, len(property_depict)): #get the mainsnak dictionary\n",
    "                try:\n",
    "                    wikidata_num = property_depict[dict_place]['mainsnak']['datavalue']['value']['id'] #get the wikidata number \n",
    "\n",
    "                    params_2 = {\n",
    "                        \"action\": \"wbgetentities\", #Gets the data for multiple Wikibase entities.\n",
    "                        \"ids\": str(wikidata_num),\n",
    "                        \"props\": \"labels\",\n",
    "                        \"languages\": \"en\",\n",
    "                        \"format\": \"json\",\n",
    "                    }\n",
    "\n",
    "                    response_2 = session.get(params_2) #get request for the wikiapi to get information about the wikidata number got\n",
    "                    depicts = response_2.get('entities', 'XX').get(wikidata_num).get('labels', 'XX').get('en', 'XX') #The names of the properties to get back from each entity. Will be further filtered by any languages given.\n",
    "                    \n",
    "                    if \"XX\" not in str(depicts):\n",
    "                        info = str(depicts['value']) + \" (\" + str(wikidata_num) + \")\" #gets the depict value and their respective wikidata number\n",
    "                        #depictslist.append(info)\n",
    "                        wikidata_list.append(wikidata_num)\n",
    "                        \n",
    "                except:\n",
    "                    continue \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    new_wikidata_list=list(set([list_item for list_item in wikidata_list])) #further ensure the wikidata numbers in the list are unique\n",
    "    \n",
    "    '''for list_item in wikidata_list:\n",
    "        \n",
    "        if list_item not in new_wikidata_list: \n",
    "            new_wikidata_list.append()'''\n",
    "            \n",
    "    return new_wikidata_list\n",
    "            \n",
    "#get_wikidata('Category:Images by Prburley in Wiki Loves Monuments 2021 in Brazil', lang='commons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25adaef-980b-4298-a51b-26a52ff7aa9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this function gets the label and description of selected properties(i chose properties depicted in the cultu)\n",
    "\n",
    "def get_labels_description_subcat(cat, lang) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    labels and description of the location, heritage, street address, and description of unique wikidata item for each image in all subcategory of a category of interest \n",
    "\n",
    "    Args:\n",
    "        cat (string): the title/name of the category of interest\n",
    "        lang(string): the particular wikipedia api needed eg en, fr, commons\n",
    "\n",
    "    Returns:\n",
    "         response_item[response_keys]['value'] (string): the value of the labels and description of the location, heritage, street address, and description for each wikidata id in a category\n",
    "    \"\"\"\n",
    "    \n",
    "    session = mwapi.Session(\n",
    "        host=\"https://{0}.wikimedia.org/w/api.php\".format(lang),\n",
    "        user_agent=\"Outreachy round fall 2022\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "            \"action\": \"query\",\n",
    "            \"list\":\"categorymembers\", #Get information about all categories used in the page\n",
    "            \"cmtitle\": cat,\n",
    "            \"cmlimit\": \"max\", #number of subcategories to return, the default value is 10\n",
    "            \"cmtype\": 'subcat', #get sub categories in a category\n",
    "            \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = session.get(params) #get request for the wikiapi to get the category members pageid\n",
    "    category_member = (response['query']['categorymembers']) #get the list of all the subcategories\n",
    "\n",
    "    for category_item in category_member:\n",
    "         \n",
    "        try:\n",
    "           \n",
    "            wikidata_list = get_wikidata(category_item['title'], lang)\n",
    "            print('\\n', category_item['title'])\n",
    "            \n",
    "            for wikidata_item in wikidata_list:\n",
    "\n",
    "                sparql = \"\"\"\n",
    "                SELECT \n",
    "                     ?item ?itemLabel ?itemDescription \n",
    "                      ?locationLabel ?locationDescription  \n",
    "                      ?streetLabel  \n",
    "                      ?descriptionLabel \n",
    "                      ?heritageLabel\n",
    "                    WHERE {\n",
    "                      VALUES ?item { wd:\"\"\"+wikidata_item+\"\"\" }\n",
    "                      ?item wdt:P131 ?location ;\n",
    "                            wdt:P1435 ?heritage .\n",
    "                      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "                      OPTIONAL {?item \n",
    "                            wdt:P6375 ?street ;\n",
    "                            wdt:P973 ?description ;}\n",
    "                    }\n",
    "                \"\"\"\n",
    "\n",
    "                wikiquery = SparqlQuery() #sparqlquery that allows the use of sparql queries with python\n",
    "                response = wikiquery.query(sparql)\n",
    "                results = response['results']['bindings'] #get list of all the response results\n",
    "\n",
    "                for response_item in results:\n",
    "\n",
    "                    for response_keys in list(response_item.keys()):\n",
    "                        print(response_keys, ' -> ', response_item[response_keys]['value'])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "#get_labels_description_subcat('Category:Top_contributors_of_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d8906-9e52-4348-aee3-9a8cc292d2d4",
   "metadata": {},
   "source": [
    "# Running these functions on a list of files in a subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44614c02-00a8-4058-a14a-8c7c203cb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of commons files selected\n",
    "\n",
    "files_list = get_all_files_subcat('Category:Images_by_Ana_Beatriz_Sampaio_in_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')\n",
    "\n",
    "for title in files_list: #loops through the list of commons files\n",
    "    print(title, ' -> ', get_categories_list(title, lang='commons'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd9f3f-94b3-46cd-9a60-ba113f6f421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of commons files selected\n",
    "\n",
    "files_list = get_all_files_subcat('Category:Images_by_Ana_Beatriz_Sampaio_in_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')\n",
    "\n",
    "for title in files_list: #loops through the list of commons files\n",
    "    print(title, ' -> ', get_hidden_categories_list(title, lang='commons'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe6ef6-7d50-4e02-af0a-cec32e0e64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of commons files selected\n",
    "\n",
    "files_list = get_all_files_subcat('Category:Images_by_Ana_Beatriz_Sampaio_in_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')\n",
    "\n",
    "for title in files_list: #loops through the list of commons files\n",
    "    get_all_files_data(title, lang='commons')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5998f-91db-43e7-9137-a78dc44ada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of commons files selected\n",
    "\n",
    "files_list = get_all_files_subcat('Category:Images_by_Ana_Beatriz_Sampaio_in_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')\n",
    "\n",
    "for title in files_list:  #loops through the list of commons files\n",
    "    get_metadata_item(title, lang='commons')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088023e-f691-41b8-939d-43c465bf0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of commons files selected\n",
    "\n",
    "files_list = get_all_files_subcat('Category:Images_by_Ana_Beatriz_Sampaio_in_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')\n",
    "\n",
    "for title in files_list:  #loops through the list of commons files\n",
    "    \n",
    "    all_categories_list = get_categories_list(title, lang='commons') + get_hidden_categories_list(title, lang='commons') #get all the categories that is, the hidden plus the unhidden categories\n",
    "    print(all_categories_list)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d143164-6316-4123-a50f-453cda05ef4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_list = get_all_files_subcat('Category:Images_by_Ana_Beatriz_Sampaio_in_Wiki_Loves_Monuments_2021_in_Brazil', lang='commons')\n",
    "\n",
    "all_category=[]\n",
    "for title in files_list:  #loops through the list of commons files\n",
    "    all_categories_list = get_categories_list(title, lang='commons') + get_hidden_categories_list(title, lang='commons') #get all the categories that is, the hidden plus the unhidden categories\n",
    "    all_category += all_categories_list\n",
    "    \n",
    "new_all_category_list=list(set([list_item for list_item in all_category])) #list got from the addition of all the hidden and unhidden category list is filtered to remove category repetition and further ensure the categories in the list are unique to avoid repetition\n",
    "        \n",
    "for cat in all_categories_list: #looping through the list\n",
    "    \n",
    "    if 'Category:Pages with maps' not in cat: #category:pages with maps, amongst others have no entities so this filters it out\n",
    "        try:\n",
    "            info = get_labels_description_subcat(cat, lang='commons')\n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "print('\\n', info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838b552-ef97-49ca-9182-0319ccf4d128",
   "metadata": {},
   "source": [
    "# Thoughts:\n",
    "\n",
    "The function get_all_files_subcat gives a list of files in a subcategory while get_all_files_cat gives a list of all files in all the subcategory present in the category. This is to prevent hard coding any file name or subcategory. The function get_all_files_cat still goes through further filter the list to ensure no repetition of the wikidata id. Also the all_category list got from the addition of all the hidden and unhidden category list is filtered to remove category repetition. \n",
    "\n",
    "All these functions ensures that we get all the details from a category/files with or without subcategory. The function get_labels_description_subcat is used to extract information present in the cultural property which cannot be got from the mediawiki api (iwlink gives the wikidata id) as well as the wikidata label and description and other necessary information that might be of use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca850d-f478-4d11-abd7-42af59aa7ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
